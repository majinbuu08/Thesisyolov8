{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49bb732-974c-4ab7-8670-b4be47d476bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 368.9ms\n",
      "Speed: 16.2ms preprocess, 368.9ms inference, 14.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 486.3ms\n",
      "Speed: 15.1ms preprocess, 486.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 463.0ms\n",
      "Speed: 6.1ms preprocess, 463.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 481.5ms\n",
      "Speed: 8.5ms preprocess, 481.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 264.2ms\n",
      "Speed: 4.0ms preprocess, 264.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 250.9ms\n",
      "Speed: 6.7ms preprocess, 250.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 246.3ms\n",
      "Speed: 4.0ms preprocess, 246.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 240.8ms\n",
      "Speed: 5.5ms preprocess, 240.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 234.5ms\n",
      "Speed: 4.2ms preprocess, 234.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 563.1ms\n",
      "Speed: 6.0ms preprocess, 563.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 580.9ms\n",
      "Speed: 10.5ms preprocess, 580.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 513.4ms\n",
      "Speed: 8.4ms preprocess, 513.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 181.6ms\n",
      "Speed: 3.6ms preprocess, 181.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 190.5ms\n",
      "Speed: 5.2ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 229.1ms\n",
      "Speed: 5.0ms preprocess, 229.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 226.6ms\n",
      "Speed: 3.6ms preprocess, 226.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 227.5ms\n",
      "Speed: 6.3ms preprocess, 227.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 226.3ms\n",
      "Speed: 4.9ms preprocess, 226.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 189.6ms\n",
      "Speed: 4.5ms preprocess, 189.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 173.9ms\n",
      "Speed: 5.0ms preprocess, 173.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 186.8ms\n",
      "Speed: 5.6ms preprocess, 186.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 179.9ms\n",
      "Speed: 4.6ms preprocess, 179.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.4ms\n",
      "Speed: 3.8ms preprocess, 202.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 247.5ms\n",
      "Speed: 8.0ms preprocess, 247.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 209.7ms\n",
      "Speed: 5.5ms preprocess, 209.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 277.4ms\n",
      "Speed: 4.7ms preprocess, 277.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 183.6ms\n",
      "Speed: 3.2ms preprocess, 183.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 192.9ms\n",
      "Speed: 4.5ms preprocess, 192.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 199.6ms\n",
      "Speed: 6.3ms preprocess, 199.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 180.4ms\n",
      "Speed: 4.0ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 199.7ms\n",
      "Speed: 4.2ms preprocess, 199.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 186.7ms\n",
      "Speed: 6.6ms preprocess, 186.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 156.4ms\n",
      "Speed: 4.5ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.7ms\n",
      "Speed: 3.0ms preprocess, 183.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 198.7ms\n",
      "Speed: 2.0ms preprocess, 198.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 189.4ms\n",
      "Speed: 7.5ms preprocess, 189.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 173.1ms\n",
      "Speed: 3.0ms preprocess, 173.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 184.3ms\n",
      "Speed: 3.5ms preprocess, 184.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 216.0ms\n",
      "Speed: 3.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 204.4ms\n",
      "Speed: 2.0ms preprocess, 204.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 166.2ms\n",
      "Speed: 2.0ms preprocess, 166.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 215.0ms\n",
      "Speed: 4.0ms preprocess, 215.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 238.9ms\n",
      "Speed: 4.0ms preprocess, 238.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 150.5ms\n",
      "Speed: 2.0ms preprocess, 150.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 167.9ms\n",
      "Speed: 2.5ms preprocess, 167.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 184.8ms\n",
      "Speed: 3.0ms preprocess, 184.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 213.8ms\n",
      "Speed: 4.0ms preprocess, 213.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 179.4ms\n",
      "Speed: 4.0ms preprocess, 179.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 206.7ms\n",
      "Speed: 3.0ms preprocess, 206.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 198.2ms\n",
      "Speed: 2.5ms preprocess, 198.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 231.9ms\n",
      "Speed: 3.0ms preprocess, 231.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 235.0ms\n",
      "Speed: 2.9ms preprocess, 235.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 200.3ms\n",
      "Speed: 3.9ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 197.9ms\n",
      "Speed: 3.1ms preprocess, 197.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 199.4ms\n",
      "Speed: 3.1ms preprocess, 199.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 191.5ms\n",
      "Speed: 1.9ms preprocess, 191.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 166.4ms\n",
      "Speed: 2.9ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 200.1ms\n",
      "Speed: 3.5ms preprocess, 200.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 180.4ms\n",
      "Speed: 3.5ms preprocess, 180.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 176.1ms\n",
      "Speed: 4.0ms preprocess, 176.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 229.9ms\n",
      "Speed: 3.0ms preprocess, 229.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 187.6ms\n",
      "Speed: 3.7ms preprocess, 187.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 210.8ms\n",
      "Speed: 4.0ms preprocess, 210.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 201.5ms\n",
      "Speed: 4.5ms preprocess, 201.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 175.8ms\n",
      "Speed: 3.9ms preprocess, 175.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 197.2ms\n",
      "Speed: 3.0ms preprocess, 197.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 177.1ms\n",
      "Speed: 2.0ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 160.9ms\n",
      "Speed: 2.5ms preprocess, 160.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 155.8ms\n",
      "Speed: 2.6ms preprocess, 155.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 152.4ms\n",
      "Speed: 2.0ms preprocess, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 150.1ms\n",
      "Speed: 1.1ms preprocess, 150.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 219.8ms\n",
      "Speed: 2.9ms preprocess, 219.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 226.5ms\n",
      "Speed: 3.0ms preprocess, 226.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 194.9ms\n",
      "Speed: 3.0ms preprocess, 194.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 134.8ms\n",
      "Speed: 3.0ms preprocess, 134.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 203.1ms\n",
      "Speed: 3.2ms preprocess, 203.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 197.0ms\n",
      "Speed: 3.0ms preprocess, 197.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 147.3ms\n",
      "Speed: 4.2ms preprocess, 147.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 130.2ms\n",
      "Speed: 2.0ms preprocess, 130.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 125.7ms\n",
      "Speed: 2.0ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 135.5ms\n",
      "Speed: 3.0ms preprocess, 135.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 126.3ms\n",
      "Speed: 2.0ms preprocess, 126.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 137.5ms\n",
      "Speed: 2.0ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 142.4ms\n",
      "Speed: 3.0ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 183.3ms\n",
      "Speed: 2.0ms preprocess, 183.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 202.6ms\n",
      "Speed: 3.5ms preprocess, 202.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 211.0ms\n",
      "Speed: 3.0ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 188.5ms\n",
      "Speed: 3.0ms preprocess, 188.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 154.1ms\n",
      "Speed: 3.6ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 188.6ms\n",
      "Speed: 2.0ms preprocess, 188.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 201.6ms\n",
      "Speed: 4.0ms preprocess, 201.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 149.7ms\n",
      "Speed: 3.0ms preprocess, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 188.0ms\n",
      "Speed: 3.0ms preprocess, 188.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 211.1ms\n",
      "Speed: 3.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 195.0ms\n",
      "Speed: 3.3ms preprocess, 195.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 208.7ms\n",
      "Speed: 3.0ms preprocess, 208.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 181.1ms\n",
      "Speed: 3.5ms preprocess, 181.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 215.4ms\n",
      "Speed: 4.0ms preprocess, 215.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 222.8ms\n",
      "Speed: 3.5ms preprocess, 222.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 173.7ms\n",
      "Speed: 4.0ms preprocess, 173.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 217.2ms\n",
      "Speed: 4.4ms preprocess, 217.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 163.8ms\n",
      "Speed: 3.0ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.9ms\n",
      "Speed: 2.6ms preprocess, 195.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 163.6ms\n",
      "Speed: 2.0ms preprocess, 163.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 146.4ms\n",
      "Speed: 1.6ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 182.1ms\n",
      "Speed: 2.0ms preprocess, 182.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 167.0ms\n",
      "Speed: 2.0ms preprocess, 167.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 191.5ms\n",
      "Speed: 1.0ms preprocess, 191.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 213.1ms\n",
      "Speed: 3.0ms preprocess, 213.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 189.3ms\n",
      "Speed: 2.5ms preprocess, 189.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 158.5ms\n",
      "Speed: 2.0ms preprocess, 158.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 172.2ms\n",
      "Speed: 3.0ms preprocess, 172.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 169.1ms\n",
      "Speed: 2.0ms preprocess, 169.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.7ms\n",
      "Speed: 1.9ms preprocess, 148.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 169.2ms\n",
      "Speed: 3.4ms preprocess, 169.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 194.0ms\n",
      "Speed: 2.0ms preprocess, 194.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 173.6ms\n",
      "Speed: 2.3ms preprocess, 173.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 184.4ms\n",
      "Speed: 3.5ms preprocess, 184.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.1ms\n",
      "Speed: 4.0ms preprocess, 137.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 189.2ms\n",
      "Speed: 4.3ms preprocess, 189.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 198.2ms\n",
      "Speed: 3.0ms preprocess, 198.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 192.7ms\n",
      "Speed: 3.5ms preprocess, 192.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 220.9ms\n",
      "Speed: 3.5ms preprocess, 220.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 205.9ms\n",
      "Speed: 2.9ms preprocess, 205.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 189.9ms\n",
      "Speed: 3.0ms preprocess, 189.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 186.7ms\n",
      "Speed: 3.0ms preprocess, 186.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 203.4ms\n",
      "Speed: 3.0ms preprocess, 203.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 221.1ms\n",
      "Speed: 3.9ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 221.6ms\n",
      "Speed: 3.4ms preprocess, 221.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 233.0ms\n",
      "Speed: 3.2ms preprocess, 233.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 223.1ms\n",
      "Speed: 3.0ms preprocess, 223.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 217.7ms\n",
      "Speed: 3.0ms preprocess, 217.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 233.4ms\n",
      "Speed: 4.0ms preprocess, 233.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 185.9ms\n",
      "Speed: 2.1ms preprocess, 185.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 203.7ms\n",
      "Speed: 2.1ms preprocess, 203.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 228.9ms\n",
      "Speed: 3.0ms preprocess, 228.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 221.8ms\n",
      "Speed: 3.4ms preprocess, 221.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 211.3ms\n",
      "Speed: 3.5ms preprocess, 211.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 201.1ms\n",
      "Speed: 3.0ms preprocess, 201.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 240.6ms\n",
      "Speed: 3.7ms preprocess, 240.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 233.8ms\n",
      "Speed: 3.5ms preprocess, 233.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 192.4ms\n",
      "Speed: 3.0ms preprocess, 192.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 218.1ms\n",
      "Speed: 3.5ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 221.8ms\n",
      "Speed: 3.5ms preprocess, 221.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 220.4ms\n",
      "Speed: 5.8ms preprocess, 220.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 192.3ms\n",
      "Speed: 3.6ms preprocess, 192.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 205.5ms\n",
      "Speed: 5.0ms preprocess, 205.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 216.4ms\n",
      "Speed: 3.0ms preprocess, 216.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 239.8ms\n",
      "Speed: 4.0ms preprocess, 239.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 240.0ms\n",
      "Speed: 2.6ms preprocess, 240.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 190.0ms\n",
      "Speed: 3.0ms preprocess, 190.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 213.5ms\n",
      "Speed: 3.0ms preprocess, 213.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 222.0ms\n",
      "Speed: 3.6ms preprocess, 222.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 258.3ms\n",
      "Speed: 3.0ms preprocess, 258.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 223.2ms\n",
      "Speed: 4.0ms preprocess, 223.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 196.8ms\n",
      "Speed: 4.0ms preprocess, 196.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 193.8ms\n",
      "Speed: 4.0ms preprocess, 193.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 178.5ms\n",
      "Speed: 2.3ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 241.8ms\n",
      "Speed: 3.4ms preprocess, 241.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 186.8ms\n",
      "Speed: 3.0ms preprocess, 186.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 162.2ms\n",
      "Speed: 3.1ms preprocess, 162.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 201.1ms\n",
      "Speed: 3.1ms preprocess, 201.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 216.4ms\n",
      "Speed: 4.0ms preprocess, 216.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 167.3ms\n",
      "Speed: 2.9ms preprocess, 167.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 147.1ms\n",
      "Speed: 3.5ms preprocess, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 167.0ms\n",
      "Speed: 3.5ms preprocess, 167.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 198.0ms\n",
      "Speed: 3.3ms preprocess, 198.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 213.7ms\n",
      "Speed: 2.9ms preprocess, 213.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 237.6ms\n",
      "Speed: 4.0ms preprocess, 237.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 214.3ms\n",
      "Speed: 3.9ms preprocess, 214.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 217.6ms\n",
      "Speed: 4.3ms preprocess, 217.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 184.9ms\n",
      "Speed: 5.0ms preprocess, 184.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 170.6ms\n",
      "Speed: 2.5ms preprocess, 170.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 179.8ms\n",
      "Speed: 3.5ms preprocess, 179.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 148.0ms\n",
      "Speed: 2.6ms preprocess, 148.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 171.4ms\n",
      "Speed: 2.0ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 123.5ms\n",
      "Speed: 2.0ms preprocess, 123.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 137.2ms\n",
      "Speed: 2.0ms preprocess, 137.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 162.2ms\n",
      "Speed: 2.5ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 160.7ms\n",
      "Speed: 1.0ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 228.2ms\n",
      "Speed: 3.0ms preprocess, 228.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 188.1ms\n",
      "Speed: 1.7ms preprocess, 188.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 194.7ms\n",
      "Speed: 1.9ms preprocess, 194.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 210.8ms\n",
      "Speed: 2.0ms preprocess, 210.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 209.8ms\n",
      "Speed: 2.3ms preprocess, 209.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 236.6ms\n",
      "Speed: 2.0ms preprocess, 236.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 203.3ms\n",
      "Speed: 3.2ms preprocess, 203.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 172.1ms\n",
      "Speed: 2.0ms preprocess, 172.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 173.8ms\n",
      "Speed: 3.4ms preprocess, 173.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 124.6ms\n",
      "Speed: 2.5ms preprocess, 124.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 196.1ms\n",
      "Speed: 4.0ms preprocess, 196.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 167.5ms\n",
      "Speed: 3.5ms preprocess, 167.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 173.5ms\n",
      "Speed: 3.0ms preprocess, 173.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 175.9ms\n",
      "Speed: 2.0ms preprocess, 175.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 185.7ms\n",
      "Speed: 2.6ms preprocess, 185.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 166.1ms\n",
      "Speed: 4.0ms preprocess, 166.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 209.4ms\n",
      "Speed: 3.0ms preprocess, 209.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 206.5ms\n",
      "Speed: 3.0ms preprocess, 206.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 227.8ms\n",
      "Speed: 3.0ms preprocess, 227.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 211.9ms\n",
      "Speed: 2.0ms preprocess, 211.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 221.6ms\n",
      "Speed: 2.0ms preprocess, 221.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 191.7ms\n",
      "Speed: 3.0ms preprocess, 191.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 186.4ms\n",
      "Speed: 3.0ms preprocess, 186.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 195.3ms\n",
      "Speed: 3.0ms preprocess, 195.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 182.0ms\n",
      "Speed: 4.0ms preprocess, 182.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 174.8ms\n",
      "Speed: 3.0ms preprocess, 174.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 165.0ms\n",
      "Speed: 2.0ms preprocess, 165.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 175.6ms\n",
      "Speed: 4.0ms preprocess, 175.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 187.1ms\n",
      "Speed: 3.7ms preprocess, 187.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m detected_boxes \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# Dictionary to store the highest confidence box for each class\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Class Name\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:251\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 251\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:137\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minference\u001b[39m(\u001b[38;5;28mself\u001b[39m, im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    135\u001b[0m     visualize \u001b[38;5;241m=\u001b[39m increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem,\n\u001b[0;32m    136\u001b[0m                                mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:334\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    331\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize) \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mor\u001b[39;00m visualize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:45\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:62\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:82\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m     83\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:182\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    180\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:42\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,  1024)\n",
    "cap.set(4,  600)\n",
    "\n",
    "model = YOLO(\"C:\\\\Users\\\\jdich\\\\thesisnew\\\\runs\\\\detect\\\\train2\\\\weights\\\\best.pt\")\n",
    "\n",
    "classNames = ['person']\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    detected_boxes = {}  # Dictionary to store the highest confidence box for each class\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            if classNames[cls] == 'person':  # Only consider 'person' class\n",
    "                # Confidence\n",
    "                conf = box.conf[0]\n",
    "                if conf > detected_boxes.get(cls, 0):\n",
    "                    detected_boxes[cls] = conf\n",
    "                    # Bounding Box\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    w, h = x2 - x1, y2 - y1\n",
    "                    cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "                    cvzone.putTextRect(img, f'{classNames[cls]} {conf:.2f}', (max(0, x1), max(35, y1)), scale=0.9, thickness=2)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e8b61e-0741-4136-9d27-4301125d4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics==8.0.140 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (8.0.140)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: streamlit==1.23.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.23.1)\n",
      "Requirement already satisfied: cvzone==1.5.6 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.5.6)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
      "Requirement already satisfied: numpy==1.25.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.25.1)\n",
      "Requirement already satisfied: Pillow==9.4.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (9.4.0)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
      "Requirement already satisfied: scipy==1.10.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (1.10.0)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (2.0.1)\n",
      "Requirement already satisfied: torchvision==0.15.2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (0.15.2)\n",
      "Requirement already satisfied: tqdm==4.65.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (4.65.0)\n",
      "Requirement already satisfied: filterpy==1.1.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: scikit-image==0.21.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (0.21.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from ultralytics==8.0.140->-r requirements.txt (line 1)) (4.9.0.80)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from ultralytics==8.0.140->-r requirements.txt (line 1)) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from ultralytics==8.0.140->-r requirements.txt (line 1)) (0.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from ultralytics==8.0.140->-r requirements.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (6.11.0)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (4.25.2)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (14.0.2)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (8.2.2)\n",
      "Requirement already satisfied: toml<2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (4.3.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (3.1.41)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\jdich\\appdata\\roaming\\python\\python311\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (6.4)\n",
      "Requirement already satisfied: watchdog in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from streamlit==1.23.1->-r requirements.txt (line 2)) (2.1.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 4)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from matplotlib==3.7.1->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 8)) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from torch==2.0.1->-r requirements.txt (line 10)) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from torch==2.0.1->-r requirements.txt (line 10)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from torch==2.0.1->-r requirements.txt (line 10)) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from torch==2.0.1->-r requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from tqdm==4.65.0->-r requirements.txt (line 12)) (0.4.6)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from scikit-image==0.21.0->-r requirements.txt (line 14)) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from scikit-image==0.21.0->-r requirements.txt (line 14)) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from scikit-image==0.21.0->-r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from scikit-image==0.21.0->-r requirements.txt (line 14)) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3->streamlit==1.23.1->-r requirements.txt (line 2)) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit==1.23.1->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.140->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.140->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 10)) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2->streamlit==1.23.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jdich\\appdata\\roaming\\python\\python311\\site-packages (from rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 2)) (2.17.2)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit==1.23.1->-r requirements.txt (line 2)) (0.1.0.post0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit==1.23.1->-r requirements.txt (line 2)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.23.1->-r requirements.txt (line 2)) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jdich\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 2)) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810e467-9190-47de-b402-487477e9331b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
